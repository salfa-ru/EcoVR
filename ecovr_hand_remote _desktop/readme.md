# Управление курсором мыши положением кисти руки на изображении с веб-камеры


## Модуль HandPointModule
содержит классы HandPoint и HandPoints инкапсулирующие в себе значения для точек  руки для дальнейшей более удобной с ними работы. содержит логику правильного положения руки на камере по углу между точками оснований указательного пальца и мизинца с вершиной в основании кисти и величины вертикальной позиции основания пальцев к основанию кисти руки

----

## Модуль HandDetectorModule

1. `mode` статический режим (False)
2. `max_hands` максимально определяемое количество рук (1)
3. `tracking` точность отслеживания (0.5)
4. `detection` точность детектирования (0.5)

### def find_hands()
#### поиск руки
принимает исходное изображение, запоминает результаты, изображение возвращает в исходном виде  

### def detect_position()
#### фиксирование точек на руке 
принимает исходное изображение, запоминает результаты, изображение возвращает в исходном виде 

### def draw_point()
#### рисует круг в указанной точке
принимает исходное изображение, точку руки, радиус круга, цвет круга, возвращает новое изображение

### def draw_line()
#### рисует линию между указанными точками
принимает исходное изображение, 2 точки руки, цвет и толщину линии, возвращает новое изображение

### def draw_text()
#### рисует рисует текст в заданных координатах
принимает исходное изображение, сообщение, точку и цвет сообщения, возвращает новое изображение

### draw_connection()
#### рисует стандартное изображение экзоскелета для кисти
принимает исходное изображение, возвращает новое изображение

-----

## Модуль MouseHandRemoteModule

Основной модуль управления содержит всю основную логику
Основные настройки при инициализации
- `non_sensitivity_zone_hor` -> зона не чувствительности для горизонтального перемещения курсора;
- `non_sensitivity_zone_ver` -> зона не чувствительности для вертикального перемещения курсора;
- `non_sensitivity_zone_left_click` -> зона не чувствительности для сработки левого клика;
- `non_sensitivity_zone_right_click` -> зона не чувствительности для сработки правого клика;
- `non_sensitivity_zone_wheel` -> зона не чувствительности для сработки скроллинга
- `mouse_wheel_speed` -> скорость скроллинга колесом мыши

### 'def remote()'
#### управление курсором

входные параметры:
- `hand_points:HandPoints` -> задетектированные точки руки
- `smooth:int` -> сглаживание

1. если ничего не задетектировано -> выход
2. делаем калибровочный замер
3. если положение руки верно включаем управление
4. если поднят мизинец - включаем перемещение
    1. двигаем курсор по горизонтали по положению большого пальца
    2. двигаем курсор по вертикали по положению среднего пальца
5. если режим перемещения выключен
    1. измеряем расстояние между средним и большим пальцем - при малом вызываем правый клик
    2. делаем скроллинг по положению указательного пальца
6. вне зависимости от режима перемещения
    1. измеряем расстояние между указательным и большим пальцем - при малом вызываем левый клик

### def displaying_info
#### вывод отладочной информации

  1. `calibration distance` - калибровочное расстояние
  2. `horizontal` - горизонтальное перемещение сигнал - величина зоны не чувствительности
  3. `vertical` - вертикальное перемещение сигнал - величина зоны не чувствительности
  4. `mouse` - позиция курсора на экране
  5. `right click distance` - дистанция для детектировании правого клика - величина зоны не чувствительности
  6. `left click distance` - дистанция для детектировании левого клика - величина зоны не чувствительности
  7. `wheel distance` - расстояние для сработки скроллинга


-----
# Example `main.py`
```
cap = cv2.VideoCapture(0)
if cap.isOpened():           
    hand_remote = MouseHandRemote() 
    detector = HandDetector(max_hands=1, detection=0.7, tracking=0.5) 
    while True:
        _, img = cap.read()
        img = cv2.flip(img, 1) 
        img = detector.find_hands(img)  
        hand_points = detector.detect_position(img) 
        hand_remote.remote(hand_points) 
        hand_remote.displaying_info(img, detector) 
        cv2.imshow("preview", img) 
        if cv2.waitKey(1) & 0xFF == 27:  
            break
else:
    print('webcam is not available')
```

1. Берем камеру по умолчанию установленную первой в системе
    ```
        cap = cv2.VideoCapture(0)
    ```
2. проверяем доступна ли камера 
    ``` 
        if cap.isOpened():           
            ...
        else:
            print('webcam is not available')
    ```
3. готовим обработку
    ```
        hand_remote = MouseHandRemote() 
        detector = HandDetector(detection=0.7) 
    ```
4. далее в цикле читаем кадр и отражаем по горизонтали
    ```
        img = cv2.flip(img, 1) 
        img = detector.find_hands(img) 
    ```
5. детектируем точки на руке 
    ```
        hand_points = detector.detect_position(img)
    ```
6. включаем управление передав найденные точки
    ```
        hand_remote.remote(hand_points)
    ```
7. при необходимости выводим рисуем отладочную информацию на кадр
    ```
        hand_remote.displaying_info(img, detector)
    ```    
8. показываем кадр в окне (не обязательно) и ждем 1мс нажатия клавиши ESC 
    ```
        if cv2.waitKey(1) & 0xFF == 27:  
            break
    ```
